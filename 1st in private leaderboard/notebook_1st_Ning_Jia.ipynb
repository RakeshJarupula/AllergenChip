{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Description\n",
    "\n",
    "* This is only the submission for the test dataset pipeline. There are separate files for EDA and training. I will provide them if requested.\n",
    "* The models will treat this multi labels problem as multiple separate binary classification problems.\n",
    "* The submission is from ensembled models built with LightGBM and Catboost. Iâ€™ve tried many other binary classification algorithms, and only LightGBM and Catboost have performed well so far. I also tried to model the label associations by building a second layer model to stack all the binary classifications output. But ensembling model predictions by weighted average outperforms stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2989, 365), (586, 337))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')\n",
    "train_raw.shape, test_raw.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix outliers and errors\n",
    "train_raw.loc[train_raw['Age_of_onsets'].str.strip()=='2, 3','Age_of_onsets'] = 2\n",
    "train_raw['Age_of_onsets'] = train_raw['Age_of_onsets'].str.strip().fillna(9).astype(np.int16)\n",
    "\n",
    "train_raw.loc[train_raw['Treatment_of_rhinitis']=='1.3','Treatment_of_rhinitis'] = '1,3'\n",
    "train_raw.loc[train_raw['Treatment_of_rhinitis']=='2.3','Treatment_of_rhinitis'] = '2,3'\n",
    "test_raw.loc[test_raw['Treatment_of_rhinitis']=='2.3','Treatment_of_rhinitis'] = '1,3'\n",
    "\n",
    "train_raw['Treatment_of_rhinitis'] = train_raw['Treatment_of_rhinitis'].astype(str)\n",
    "test_raw['Treatment_of_rhinitis'] = test_raw['Treatment_of_rhinitis'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have many target columns, here are the definitions\n",
    "invalid_target_cols = ['Type_of_Food_Allergy_Other','Type_of_Food_Allergy_Cereals_&_Seeds']\n",
    "\n",
    "valid_target_cols = ['Allergy_Present','Severe_Allergy','Respiratory_Allergy','Food_Allergy','Venom_Allergy','Type_of_Respiratory_Allergy_ARIA',\n",
    "               'Type_of_Respiratory_Allergy_CONJ','Type_of_Respiratory_Allergy_GINA','Type_of_Respiratory_Allergy_IGE_Pollen_Gram',\n",
    "               'Type_of_Respiratory_Allergy_IGE_Pollen_Herb','Type_of_Respiratory_Allergy_IGE_Pollen_Tree',\n",
    "               'Type_of_Respiratory_Allergy_IGE_Dander_Animals','Type_of_Respiratory_Allergy_IGE_Mite_Cockroach',\n",
    "               'Type_of_Respiratory_Allergy_IGE_Molds_Yeast','Type_of_Food_Allergy_Aromatics',\n",
    "               'Type_of_Food_Allergy_Egg','Type_of_Food_Allergy_Fish','Type_of_Food_Allergy_Fruits_and_Vegetables',\n",
    "               'Type_of_Food_Allergy_Mammalian_Milk','Type_of_Food_Allergy_Oral_Syndrom','Type_of_Food_Allergy_Other_Legumes',\n",
    "               'Type_of_Food_Allergy_Peanut','Type_of_Food_Allergy_Shellfish','Type_of_Food_Allergy_TPO',\n",
    "               'Type_of_Food_Allergy_Tree_Nuts','Type_of_Venom_Allergy_ATCD_Venom','Type_of_Venom_Allergy_IGE_Venom']\n",
    "\n",
    "food_target_cols = [x for x in valid_target_cols if x.find('Type_of_Food_')==0]\n",
    "resp_target_cols = [x for x in valid_target_cols if x.find('Type_of_Respiratory')==0]\n",
    "venom_target_cols = [x for x in valid_target_cols if x.find('Type_of_Venom')==0]\n",
    "general_target_cols = ['Allergy_Present','Severe_Allergy','Respiratory_Allergy','Food_Allergy','Venom_Allergy',]\n",
    "target_cols = invalid_target_cols+valid_target_cols\n",
    "len(valid_target_cols), len(invalid_target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cat_cols(df):\n",
    "    dropped_cols=['trustii_id','Patient_ID','Chip_Code','Chip_Type','Chip_Image_Name','Food_Type_0']\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    for col in ['Treatment_of_atopic_dematitis','Treatment_of_athsma','Treatment_of_rhinitis','General_cofactors']:\n",
    "        values = df[col].str.replace('.',',').str.replace(' ','').str.split(',')\n",
    "        df = df.join(pd.DataFrame.sparse.from_spmatrix(\n",
    "                        mlb.fit_transform(values),\n",
    "                        index=values.index,\n",
    "                        columns=[f'{col}_{x}' for x in mlb.classes_])).drop(col,axis=1)\n",
    "    \n",
    "    df['French_Residence_Department'] = df['French_Residence_Department'].astype('category')\n",
    "    df['French_Region'] = df['French_Region'].astype('category')\n",
    "    return df.drop(dropped_cols,axis=1,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['test'] = 0\n",
    "test_raw['test'] = 1\n",
    "\n",
    "data = process_cat_cols(pd.concat([train_raw,test_raw]).reset_index(drop=True))\n",
    "assert len(train_raw)+len(test_raw) == len(data)\n",
    "\n",
    "binary_cols = [x for x in data.columns if x.find('Treatment_of')==0 or x.find('General_cofactors')==0]\n",
    "non_signal_cols=['Age', 'Gender', 'Blood_Month_sample', 'French_Residence_Department', 'French_Region', 'Rural_or_urban_area', 'Sensitization', 'Age_of_onsets', 'Skin_Symptoms']\n",
    "signals = [x for x in data.columns if x not in binary_cols+non_signal_cols+target_cols+['test']]\n",
    "\n",
    "#total 318 test signals. there are only two types of test results. \n",
    "#one has 300 readings(ALEX), the other has 112 readings (ISAC).\n",
    "data['test_type'] = (data[signals].notna().sum(axis=1)==300).astype(np.int8)\n",
    "data['test_zero_num'] = (data[signals]==0).sum(axis=1).values\n",
    "data['no_treatment'] = (data[['Treatment_of_atopic_dematitis_0','Treatment_of_athsma_0','Treatment_of_rhinitis_0']].sum(axis=1)==3).astype(np.int8)\n",
    "\n",
    "train = data[data['test']==0]\n",
    "test = data[data['test']==1]\n",
    "\n",
    "#when Allergy_Present is zero, Respiratory_Allergy and Food_Allergy should be zero(some samples are 9)\n",
    "train.loc[train['Allergy_Present']==0,'Respiratory_Allergy'] = 0\n",
    "train.loc[train['Allergy_Present']==0,'Food_Allergy'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune for F1 metric\n",
    "\n",
    "* The models will have probability predictions for each target.\n",
    "\n",
    "* We need to predict yes/no labels. Therefore, thresholds optimized for F1 score are needed. The idea of optimizing threshold is based on quantile. \n",
    "\n",
    "* First we assume the targets from test and train have the same distribution. For instance, if people in the train has a 5% of chance of milk allergy, the same rate remains in the test dataset.\n",
    "\n",
    "* Models are tuned for AUC, which is basically the order of predictions. Suppose the target rate is 10%, then for a perfect classifier, if we pick the top 10% quantile as the threshold, we will have a perfect F1 of 1.\n",
    "\n",
    "* For a not-perfect classifier, then we will search for a multiplier which will time the target rate and obtain the best F1 score from the out-of-fold predictions. This multiplier could be smaller than 1, suggesting increasing the recall by labelling more positives. It could also be greater than 1, suggesting increasing the precision by labelling fewer positives. The search will find the best multiplier to balance the recall and precision to achieve the best F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best multiplier to get the highest f1 score\n",
    "#deviation: the test target distribution may not be same as the train\n",
    "def find_best_multiplier(y_true, y_pred, deviation=1):\n",
    "    best_score = 0\n",
    "    best_threshold = 0\n",
    "    for i in np.arange(0.6,1.4,0.01):\n",
    "        if y_true.ndim>1:            \n",
    "            score = f1_score(y_true, y_pred > np.quantile(y_pred,1-np.mean(y_true)*deviation)*i,average='macro')\n",
    "        else:\n",
    "            score = f1_score(y_true, y_pred > np.quantile(y_pred,1-np.mean(y_true)*deviation)*i)\n",
    "        if score>best_score:\n",
    "            best_score=score\n",
    "            best_threshold=i\n",
    "    return best_threshold, best_score\n",
    "\n",
    "def test_best_multiplier(y_true, y_pred, deviation_mean=1, deviation_std= 0.04, test_num=50):\n",
    "    multipliers, scores = [],[]\n",
    "    for deviation in np.random.normal(deviation_mean,deviation_std,test_num):\n",
    "        _multiplier, _score = find_best_multiplier(y_true,y_pred,deviation)\n",
    "        multipliers.append(_multiplier)\n",
    "        scores.append(_score)  \n",
    "    return np.mean(multipliers), np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food:0.85\n",
      "Resp:0.86\n",
      "Venom:0.91\n",
      "General:0.89\n",
      "Score mean:0.62\n"
     ]
    }
   ],
   "source": [
    "ensembled_models = ['lgb_auc_762','lgb_auc_760','cat_auc_758','lgb_auc_optuna_754']\n",
    "ensembled_weights = [0.6,0.2,0.1,0.1,]\n",
    "\n",
    "rows = {}\n",
    "RANDOM_NOISE = False\n",
    "\n",
    "for target_col in valid_target_cols:\n",
    "    oofs = []\n",
    "    for ensemble in ensembled_models:\n",
    "        file = f\"{ensemble}/{target_col.replace('Type_of_','')}.pkl\"\n",
    "        with open(file, 'rb') as handle:\n",
    "             saved_models = pickle.load(handle)\n",
    "        assert saved_models['target_col'] == target_col\n",
    "        oofs.append(saved_models['oof'])\n",
    "    \n",
    "    #get ensemble oof predictions and take average by the given weights\n",
    "    ensemble_oof = np.average(np.array(oofs),axis=0, weights=ensembled_weights)        \n",
    "    target_values = train[train[target_col].isin([0,1])][target_col].values    \n",
    "    \n",
    "    #find the best multiplier\n",
    "    if RANDOM_NOISE:                \n",
    "        _multiplier, _score = test_best_multiplier(target_values,ensemble_oof, deviation_mean=1.03)            \n",
    "    else:\n",
    "        _multiplier, _score = find_best_multiplier(target_values,ensemble_oof,1)        \n",
    "        \n",
    "    row = {}\n",
    "    row['multiplier'] = _multiplier\n",
    "    row['score'] = _score\n",
    "    rows[target_col] = row\n",
    "\n",
    "best_multipliers = pd.DataFrame.from_dict(rows,orient='index') \n",
    "print(f\"Food:{best_multipliers.loc[food_target_cols,'multiplier'].mean():.2f}\")\n",
    "print(f\"Resp:{best_multipliers.loc[resp_target_cols,'multiplier'].mean():.2f}\")\n",
    "print(f\"Venom:{best_multipliers.loc[venom_target_cols,'multiplier'].mean():.2f}\")\n",
    "print(f\"General:{best_multipliers.loc[general_target_cols,'multiplier'].mean():.2f}\")    \n",
    "print(f\"Score mean:{best_multipliers.loc[:,'score'].mean():.2f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Final Submission and Post-processing\n",
    "\n",
    "* First, we average the ensembled models' probability predictions based on weights.\n",
    "\n",
    "* Then, we transfer the probabilities to the final labels using the found multiplier.\n",
    "* Last, we do postprocessing based on the rules found in EDA.  Some rules are straightforward, like if Severe_Allergy is true, then Allergy_Present. Some rules with high confidence like if Type_of_Respiratory_Allergy_CONJ is true, then Type_of_Respiratory_Allergy_ARIA will very likely be true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_raw[['trustii_id']].copy()\n",
    "for col in invalid_target_cols:\n",
    "    submission[col] = 0\n",
    "\n",
    "for target_col in valid_target_cols:    \n",
    "    ensemble_pred = []\n",
    "    for ensemble in ensembled_models:\n",
    "        file = f\"{ensemble}/{target_col.replace('Type_of_','')}.pkl\"\n",
    "        with open(file, 'rb') as handle:\n",
    "             saved_models = pickle.load(handle)\n",
    "        assert saved_models['target_col'] == target_col        \n",
    "        ensemble_pred.append(saved_models['test_pred'])\n",
    "\n",
    "    target_values = train[train[target_col].isin([0,1])][target_col].values    \n",
    "    final_pred = np.average(np.array(ensemble_pred),axis=0, weights=ensembled_weights)   \n",
    "    threshold = np.quantile(final_pred,1-np.mean(target_values)) \n",
    "    \n",
    "    if target_col in food_target_cols:\n",
    "        multiplier = 0.85\n",
    "    elif target_col in resp_target_cols:\n",
    "        multiplier = 0.86\n",
    "    elif target_col in venom_target_cols:\n",
    "        multiplier = 0.91\n",
    "    else:\n",
    "        multiplier = 0.89\n",
    "    \n",
    "    if target_col in ['Food_Allergy','Respiratory_Allergy','Venom_Allergy','Allergy_Present']:\n",
    "        submission[f\"{target_col}_pred\"] = (final_pred>=threshold*multiplier).astype(np.int8)   \n",
    "    else:    \n",
    "        submission[target_col] = (final_pred>=threshold*multiplier).astype(np.int8)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add general prediction: []\n",
      "105\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "OVERRIDE = True\n",
    "\n",
    "submission.loc[submission[food_target_cols].sum(axis=1)>0,'Food_Allergy']=1\n",
    "submission.loc[submission[resp_target_cols].sum(axis=1)>0,'Respiratory_Allergy']=1\n",
    "submission.loc[submission[venom_target_cols].sum(axis=1)>0,'Venom_Allergy']=1\n",
    "#after ater new columns, set default to 0\n",
    "submission = submission.fillna(0)\n",
    "\n",
    "submission.loc[submission['Food_Allergy_pred']==1,'Food_Allergy']=1\n",
    "submission.loc[submission['Respiratory_Allergy_pred']==1,'Respiratory_Allergy']=1\n",
    "submission.loc[submission['Venom_Allergy_pred']==1,'Venom_Allergy']=1\n",
    "submission.loc[submission[['Respiratory_Allergy','Food_Allergy','Venom_Allergy']].sum(axis=1)>0,'Allergy_Present']=1\n",
    "#after ater new columns, set default to 0\n",
    "submission = submission.fillna(0)\n",
    "\n",
    "submission['Allergy_Present_before'] = submission['Allergy_Present']\n",
    "submission.loc[(submission['Allergy_Present_pred']==1) & (submission['Allergy_Present']==0),'Food_Allergy']=1\n",
    "submission.loc[(submission['Allergy_Present_pred']==1) & (submission['Allergy_Present']==0),'Respiratory_Allergy']=1\n",
    "submission.loc[submission['Allergy_Present_pred']==1,'Allergy_Present']=1\n",
    "print(f\"add general prediction: {submission[(submission['Allergy_Present_before']==0) & (submission['Allergy_Present']==1)].index.tolist()}\")\n",
    "\n",
    "#fix severe allergy\n",
    "submission.loc[submission['Allergy_Present']==0,'Severe_Allergy']=0\n",
    "#confidence==1 from association analysis\n",
    "submission.loc[submission['Type_of_Respiratory_Allergy_ARIA']==1,'Severe_Allergy']=1 \n",
    "\n",
    "if OVERRIDE:\n",
    "    #if venom allergy, set all sub types to be true\n",
    "    submission.loc[(submission[venom_target_cols].sum(axis=1)==0) & (submission['Venom_Allergy']==1),'Type_of_Venom_Allergy_ATCD_Venom']=1\n",
    "    submission.loc[(submission[venom_target_cols].sum(axis=1)==0) & (submission['Venom_Allergy']==1),'Type_of_Venom_Allergy_IGE_Venom']=1    \n",
    "    submission.loc[submission['Type_of_Respiratory_Allergy_CONJ']==1,'Severe_Allergy']=1 #confidence:0.95\n",
    "    \n",
    "print(submission[(submission[food_target_cols].sum(axis=1)==0) & (submission['Food_Allergy']==1)].shape[0])\n",
    "print(submission[(submission[resp_target_cols].sum(axis=1)==0) & (submission['Respiratory_Allergy']==1)].shape[0])\n",
    "print(submission[(submission[venom_target_cols].sum(axis=1)==0) & (submission['Venom_Allergy']==1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustii_id</th>\n",
       "      <th>Type_of_Food_Allergy_Other</th>\n",
       "      <th>Type_of_Food_Allergy_Cereals_&amp;_Seeds</th>\n",
       "      <th>Allergy_Present_pred</th>\n",
       "      <th>Severe_Allergy</th>\n",
       "      <th>Respiratory_Allergy_pred</th>\n",
       "      <th>Food_Allergy_pred</th>\n",
       "      <th>Venom_Allergy_pred</th>\n",
       "      <th>Type_of_Respiratory_Allergy_ARIA</th>\n",
       "      <th>Type_of_Respiratory_Allergy_CONJ</th>\n",
       "      <th>Type_of_Respiratory_Allergy_GINA</th>\n",
       "      <th>Type_of_Respiratory_Allergy_IGE_Pollen_Gram</th>\n",
       "      <th>Type_of_Respiratory_Allergy_IGE_Pollen_Herb</th>\n",
       "      <th>Type_of_Respiratory_Allergy_IGE_Pollen_Tree</th>\n",
       "      <th>Type_of_Respiratory_Allergy_IGE_Dander_Animals</th>\n",
       "      <th>Type_of_Respiratory_Allergy_IGE_Mite_Cockroach</th>\n",
       "      <th>Type_of_Respiratory_Allergy_IGE_Molds_Yeast</th>\n",
       "      <th>Type_of_Food_Allergy_Aromatics</th>\n",
       "      <th>Type_of_Food_Allergy_Egg</th>\n",
       "      <th>Type_of_Food_Allergy_Fish</th>\n",
       "      <th>Type_of_Food_Allergy_Fruits_and_Vegetables</th>\n",
       "      <th>Type_of_Food_Allergy_Mammalian_Milk</th>\n",
       "      <th>Type_of_Food_Allergy_Oral_Syndrom</th>\n",
       "      <th>Type_of_Food_Allergy_Other_Legumes</th>\n",
       "      <th>Type_of_Food_Allergy_Peanut</th>\n",
       "      <th>Type_of_Food_Allergy_Shellfish</th>\n",
       "      <th>Type_of_Food_Allergy_TPO</th>\n",
       "      <th>Type_of_Food_Allergy_Tree_Nuts</th>\n",
       "      <th>Type_of_Venom_Allergy_ATCD_Venom</th>\n",
       "      <th>Type_of_Venom_Allergy_IGE_Venom</th>\n",
       "      <th>Food_Allergy</th>\n",
       "      <th>Respiratory_Allergy</th>\n",
       "      <th>Venom_Allergy</th>\n",
       "      <th>Allergy_Present</th>\n",
       "      <th>Allergy_Present_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>1277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trustii_id  Type_of_Food_Allergy_Other  \\\n",
       "581        1276                           0   \n",
       "582        1277                           0   \n",
       "583        1280                           0   \n",
       "584        1281                           0   \n",
       "585        1282                           0   \n",
       "\n",
       "     Type_of_Food_Allergy_Cereals_&_Seeds  Allergy_Present_pred  \\\n",
       "581                                     0                     1   \n",
       "582                                     0                     1   \n",
       "583                                     0                     1   \n",
       "584                                     0                     1   \n",
       "585                                     0                     1   \n",
       "\n",
       "     Severe_Allergy  Respiratory_Allergy_pred  Food_Allergy_pred  \\\n",
       "581               1                         0                  1   \n",
       "582               1                         1                  0   \n",
       "583               1                         1                  0   \n",
       "584               1                         1                  1   \n",
       "585               1                         1                  1   \n",
       "\n",
       "     Venom_Allergy_pred  Type_of_Respiratory_Allergy_ARIA  \\\n",
       "581                   0                                 0   \n",
       "582                   0                                 1   \n",
       "583                   0                                 1   \n",
       "584                   0                                 1   \n",
       "585                   0                                 1   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_CONJ  Type_of_Respiratory_Allergy_GINA  \\\n",
       "581                                 0                                 0   \n",
       "582                                 0                                 0   \n",
       "583                                 1                                 0   \n",
       "584                                 1                                 1   \n",
       "585                                 0                                 0   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_IGE_Pollen_Gram  \\\n",
       "581                                            0   \n",
       "582                                            1   \n",
       "583                                            1   \n",
       "584                                            1   \n",
       "585                                            0   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_IGE_Pollen_Herb  \\\n",
       "581                                            0   \n",
       "582                                            1   \n",
       "583                                            1   \n",
       "584                                            1   \n",
       "585                                            0   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_IGE_Pollen_Tree  \\\n",
       "581                                            0   \n",
       "582                                            0   \n",
       "583                                            0   \n",
       "584                                            1   \n",
       "585                                            0   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_IGE_Dander_Animals  \\\n",
       "581                                               1   \n",
       "582                                               0   \n",
       "583                                               0   \n",
       "584                                               1   \n",
       "585                                               0   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_IGE_Mite_Cockroach  \\\n",
       "581                                               0   \n",
       "582                                               0   \n",
       "583                                               1   \n",
       "584                                               0   \n",
       "585                                               0   \n",
       "\n",
       "     Type_of_Respiratory_Allergy_IGE_Molds_Yeast  \\\n",
       "581                                            0   \n",
       "582                                            0   \n",
       "583                                            1   \n",
       "584                                            0   \n",
       "585                                            0   \n",
       "\n",
       "     Type_of_Food_Allergy_Aromatics  Type_of_Food_Allergy_Egg  \\\n",
       "581                               0                         0   \n",
       "582                               0                         0   \n",
       "583                               0                         0   \n",
       "584                               0                         0   \n",
       "585                               0                         0   \n",
       "\n",
       "     Type_of_Food_Allergy_Fish  Type_of_Food_Allergy_Fruits_and_Vegetables  \\\n",
       "581                          0                                           0   \n",
       "582                          0                                           0   \n",
       "583                          0                                           0   \n",
       "584                          0                                           0   \n",
       "585                          0                                           0   \n",
       "\n",
       "     Type_of_Food_Allergy_Mammalian_Milk  Type_of_Food_Allergy_Oral_Syndrom  \\\n",
       "581                                    0                                  0   \n",
       "582                                    0                                  0   \n",
       "583                                    0                                  0   \n",
       "584                                    0                                  0   \n",
       "585                                    0                                  1   \n",
       "\n",
       "     Type_of_Food_Allergy_Other_Legumes  Type_of_Food_Allergy_Peanut  \\\n",
       "581                                   0                            0   \n",
       "582                                   0                            0   \n",
       "583                                   0                            0   \n",
       "584                                   0                            0   \n",
       "585                                   0                            0   \n",
       "\n",
       "     Type_of_Food_Allergy_Shellfish  Type_of_Food_Allergy_TPO  \\\n",
       "581                               0                         0   \n",
       "582                               0                         0   \n",
       "583                               0                         0   \n",
       "584                               0                         0   \n",
       "585                               0                         0   \n",
       "\n",
       "     Type_of_Food_Allergy_Tree_Nuts  Type_of_Venom_Allergy_ATCD_Venom  \\\n",
       "581                               0                                 0   \n",
       "582                               0                                 0   \n",
       "583                               0                                 0   \n",
       "584                               0                                 0   \n",
       "585                               0                                 0   \n",
       "\n",
       "     Type_of_Venom_Allergy_IGE_Venom  Food_Allergy  Respiratory_Allergy  \\\n",
       "581                                0        1.0000               1.0000   \n",
       "582                                0        0.0000               1.0000   \n",
       "583                                0        0.0000               1.0000   \n",
       "584                                0        1.0000               1.0000   \n",
       "585                                0        1.0000               1.0000   \n",
       "\n",
       "     Venom_Allergy  Allergy_Present  Allergy_Present_before  \n",
       "581         0.0000           1.0000                  1.0000  \n",
       "582         0.0000           1.0000                  1.0000  \n",
       "583         0.0000           1.0000                  1.0000  \n",
       "584         0.0000           1.0000                  1.0000  \n",
       "585         0.0000           1.0000                  1.0000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert np.all(submission.loc[submission[food_target_cols].sum(axis=1)>0,'Food_Allergy']==1)\n",
    "assert np.all(submission.loc[submission[resp_target_cols].sum(axis=1)>0,'Respiratory_Allergy']==1)\n",
    "assert np.all(submission.loc[submission[venom_target_cols].sum(axis=1)>0,'Venom_Allergy']==1)\n",
    "assert np.all(submission.loc[submission[['Respiratory_Allergy','Food_Allergy','Venom_Allergy']].sum(axis=1)>0,'Allergy_Present']==1)\n",
    "assert np.all(submission[submission['Severe_Allergy']==1]['Allergy_Present']==1)\n",
    "assert np.all((submission[(submission['Allergy_Present']==1)][['Respiratory_Allergy','Food_Allergy','Venom_Allergy']]==1).sum(axis=1))\n",
    "submission[['trustii_id']+target_cols].to_csv('submission.csv',index=False)  \n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:512, Food:292\n",
      "Resp:482, Venom:12\n"
     ]
    }
   ],
   "source": [
    "print(f\"All:{len(submission[submission['Allergy_Present']==1])}, Food:{len(submission[submission['Food_Allergy']==1])}\") \n",
    "print(f\"Resp:{len(submission[submission['Respiratory_Allergy']==1])}, Venom:{len(submission[submission['Venom_Allergy']==1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7-virtualenv",
   "language": "python",
   "name": "python3.7-virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
